defaults:
  - input_encoder: triplet_encoder
  - backbone: triplet_transformer_encoder
  - optimizer: adam
  - scheduler: null
  - _self_
_target_: meds_torch.models.supervised_model.SupervisedModule.initialize

max_seq_len: ${data.max_seq_len}
token_dim: 4
vocab_size: ${data.vocab_size}
get_representations: false
task_name: ${data.task_name}
batch_size: ${data.dataloader.batch_size}

# compile model for faster training with pytorch 2.0
compile: false
