defaults:
  - input_encoder: eic_encoder
  - backbone: eic_transformer_decoder
  - zero_shot_labeler: none
  - _self_
_target_: meds_torch.models.eic_forecasting.EicForecastingModule.initialize

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 0.001
  weight_decay: 0.0

scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  _partial_: true
  mode: min
  factor: 0.1
  patience: 10

max_seq_len: ${data.max_seq_len}
token_dim: 4
vocab_size: ${data.vocab_size}
get_representations: false
task_name: ${data.task_name}
batch_size: ${data.dataloader.batch_size}
code_head:
  _target_: torch.nn.Identity
code_metadata_fp: ${data.code_metadata_fp}

# compile model for faster training with pytorch 2.0
compile: false

# sampling parameters
temperature: 1 # is the sampling temperature, `0` corresponds to greedy sampling
num_samples: 0 # number of samples to generate
eos_token_id: null # stop sampling when this token is generated
