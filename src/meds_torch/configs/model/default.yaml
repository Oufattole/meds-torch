architecture: transformer
params:
  nheads: 2
  n_layers: 1
  dim_feedforward: 2
  dropout: 0.1

embedder:
  collate_style: triplet
  token_dim: 32
  vocab_size: ${get_vocab_size:${code_metadata_fp}}
